# K6 Central Load Testing Framework

> **TypeScript Edition** ‚Äî Type-safe, Reusable, Production Ready

## ‚ö° Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Build and run load test
npm run test:sample

# 3. Or run with custom VUs
npm run test:sample:vus
```

---

## Core Idea

Build a **centralized K6 Core Framework** that can load test any API  
without having to write K6 scripts from scratch every time.

The main concept is to clearly separate into 2 parts:

- **Core Engine**  
  Reusable central logic (auth, scenario, metrics, http wrapper, report)

- **Project Configuration**  
  Things that change for each API (endpoint, payload, load profile)

> Goal:  
> clone ‚Üí config ‚Üí run ‚Üí get report

---

## üìÇ Project Structure

```
k6-core/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Core Engine (reusable)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ httpClient.ts       # HTTP wrapper + auth injection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.types.ts       # Auth type definitions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jwt.ts              # JWT authentication
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ none.ts             # No auth handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ simple.ts           # Simple sequential scenario
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flow.ts             # Flow/journey scenario
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporter/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporter.types.ts   # Report type definitions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ console.ts          # Console report output
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ json.ts             # JSON report generator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.ts              # Metrics collector
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types.ts                # Core type definitions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ projects/                   # Project Configurations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample-project/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config.ts           # Project config
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ endpoints.ts        # API endpoints
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ main.ts                     # Entry point
‚îÇ
‚îú‚îÄ‚îÄ dist/                           # Compiled JS (generated)
‚îú‚îÄ‚îÄ reports/                        # Generated reports
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ README.md
```

---

## Why This Exists

Problems encountered with traditional K6 usage:

- Duplicate scripts across multiple projects
- No standardized report format
- Teams interpret results differently
- Have to parse output manually every time

This framework is designed to:

- Make load test **output easy to read**
- Use the same report format for all APIs
- Store results for historical comparison

---

## üíé Why TypeScript?

| Benefit | Description |
|---------|-------------|
| **Auto-complete** | IDE suggests config options automatically |
| **Type Safety** | Catch config errors at compile time |
| **Refactor Friendly** | Change a type and instantly know what needs updating |
| **Team Collaboration** | Easy for teams to use because types document everything |

---

## üìÑ Create New Project

### 1. Copy sample project

```bash
cp -r src/projects/sample-project src/projects/my-api
```

### 2. Edit `config.ts`

```typescript
// src/projects/my-api/config.ts
import { ProjectConfig } from '../../core/types'

const config: ProjectConfig = {
  name: 'my-api',
  baseURL: 'https://api.myapp.com',
  load: {
    vus: 100,
    duration: '5m',
  },
  auth: {
    type: 'jwt',
    loginEndpoint: '/auth/login',
    payload: {
      username: 'loadtest',
      password: 'secret',
    },
    tokenPath: 'data.accessToken',
  },
  report: {
    output: [
      { type: 'console' },
      { type: 'json', path: './reports' },
    ],
  },
}

export default config
```

### 3. Define `endpoints.ts`

```typescript
// src/projects/my-api/endpoints.ts
import { EndpointConfig } from '../../core/types'

export const endpoints: EndpointConfig[] = [
  {
    name: 'Get Products',
    method: 'GET',
    url: '/api/products',
  },
  {
    name: 'Create Order',
    method: 'POST',
    url: '/api/orders',
    body: () => ({
      productId: 1,
      quantity: 2,
    }),
  },
]
```

### 4. Update `main.ts` import

```typescript
// src/main.ts
import config from './projects/my-api/config'
import { endpoints } from './projects/my-api/endpoints'
```

### 5. Run test

```bash
npm run test:sample
```

---

## MVP Features

### 1. Project-based Configuration

Configure via config:

- `baseURL` ‚Äî API base URL
- `load` ‚Äî VUs and duration
- `auth` ‚Äî JWT or No Auth
- `endpoints` ‚Äî API endpoints to test
- `report` ‚Äî Console / JSON output

### 2. Authentication Support

| Type | Description |
|------|-------------|
| `none` | No authentication required |
| `jwt` | Login once in setup then inject token for every request |

### 3. HTTP Wrapper

- Wrap http methods (GET, POST, PUT, DELETE)
- Auto-inject auth header
- Auto-collect metrics for every request

### 4. Scenario Runner

| Scenario | Use Case |
|----------|----------|
| `simple` | Call endpoints sequentially, repeatedly |
| `flow` | Simulate user journey (login ‚Üí browse ‚Üí purchase) |

---

## üìë Reporting

### Reports answer 3 questions:

1. **Can the system handle the load?** ‚Üí RPS, Error Rate
2. **Where is it slow?** ‚Üí Latency (avg, p95, p99)
3. **Are there errors?** ‚Üí Error Rate %

### Metrics

| Metric | Description |
|--------|-------------|
| Total Requests | Total number of requests |
| RPS | Requests per Second |
| Error Rate | % of failed requests |
| Avg Latency | Average response time |
| P95 Latency | 95th percentile |
| P99 Latency | 99th percentile |

### Report Output

#### 1. Console Summary

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  ‚ñ∏ K6 Load Test Report
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  Project:   sample-project
  Scenario:  simple
  VUs:       50
  Duration:  2m

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚ñ∏ Summary
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Total Requests:  12,000
  RPS:             100
  Error Rate:      0.3%

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚ñ∏ Latency
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Avg:             180ms
  P95:             420ms
  P99:             900ms

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Status: ‚úÖ PASSED
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

#### 2. JSON Report

```json
{
  "project": "sample-project",
  "scenario": "simple",
  "timestamp": "2025-12-16T10:30:00.000Z",
  "load": {
    "vus": 50,
    "duration": "2m"
  },
  "summary": {
    "requests": 12000,
    "rps": 100,
    "errorRate": 0.3
  },
  "latency": {
    "avg": 180,
    "p95": 420,
    "p99": 900
  }
}
```

---

## üìê How to Read and Measure Load Test Results

### ‚ñ∂ Sample Report

```json
{
  "project": "tasks-api",
  "scenario": "simple",
  "timestamp": "2025-12-16T15:03:53.490Z",
  "load": {
    "vus": 15,
    "duration": "60s"
  },
  "summary": {
    "requests": 900,
    "rps": 14.97,
    "errorRate": 0
  },
  "latency": {
    "avg": 1,
    "p95": 4,
    "p99": 8
  }
}
```

---

### ‚óÜ Field Definitions

#### Basic Information

| Field | Meaning | Example |
|-------|---------|---------|
| `project` | Project name being tested | `"tasks-api"` |
| `scenario` | Test pattern | `"simple"` = hit all endpoints sequentially |
| `timestamp` | Completion time (UTC) | `"2025-12-16T15:03:53.490Z"` |

#### Load Configuration

| Field | Meaning | Example |
|-------|---------|---------|
| `vus` | **Virtual Users** - Number of simulated users sending requests concurrently | `15` = 15 users hitting simultaneously |
| `duration` | Test duration | `"60s"` = 1 minute |

#### Summary Metrics

| Field | Meaning | Calculation |
|-------|---------|-------------|
| `requests` | Total HTTP requests | Count all requests sent |
| `rps` | **Requests Per Second** | `requests √∑ duration` (e.g., 900 √∑ 60 = 15 rps) |
| `errorRate` | % of failed requests | `(failed √∑ total) √ó 100` |

#### Latency Metrics (unit: milliseconds)

| Field | Meaning | Explanation |
|-------|---------|-------------|
| `avg` | **Average** - Mean response time | Average of all requests |
| `p95` | **95th Percentile** | 95% of requests respond within this time |
| `p99` | **99th Percentile** | 99% of requests respond within this time |

---

### ‚óÜ What is Percentile?

```
Assume 100 requests sorted by latency:

Request 1-95:    1-4ms   ‚Üê P95 = 4ms (95% respond within 4ms)
Request 96-99:   5-10ms  ‚Üê P99 = 10ms
Request 100:     50ms    ‚Üê outlier (very slow)

‚ñ∫ Why look at Percentile?
   - Average includes outliers ‚Üí may give skewed picture
   - P95/P99 tells you what "most users" experience
```

---

### ‚óè Measurement Criteria

#### Error Rate

| Error Rate | Status | Action |
|------------|--------|--------|
| **0-1%** | ‚úÖ Excellent | Pass! |
| **1-5%** | ‚ö†Ô∏è Warning | Investigate error causes |
| **>5%** | ‚ùå Problem | Needs immediate fix |

#### Latency (Response Time)

| Latency | Speed | Suitable For |
|---------|-------|--------------|
| **<50ms** | ‚úÖ Very Fast | Internal APIs, Microservices |
| **50-200ms** | ‚úÖ Good | General REST APIs |
| **200-500ms** | ‚ö†Ô∏è Acceptable | APIs with heavy DB queries |
| **>500ms** | ‚ùå Too Slow | Should optimize |

#### RPS (Throughput)

| Scenario | Expected RPS |
|----------|--------------|
| Standard API | 100-500 rps |
| High-performance API | 1,000+ rps |
| Real-time API | 5,000+ rps |

> **Note:** RPS depends on many factors such as server specs, network, database

---

### ‚òÖ Analysis Examples

#### ‚úÖ Good Results

```json
{
  "requests": 900,
  "rps": 14.97,
  "errorRate": 0,
  "latency": { "avg": 1, "p95": 4, "p99": 8 }
}
```

**Analysis:**
- Error = 0% ‚Üí No errors at all ‚úÖ
- Latency avg 1ms, p95 4ms ‚Üí Very fast ‚úÖ
- Can increase VUs to find breaking point

#### ‚ö†Ô∏è Warning Results

```json
{
  "requests": 5000,
  "rps": 83.33,
  "errorRate": 2.5,
  "latency": { "avg": 250, "p95": 800, "p99": 1500 }
}
```

**Analysis:**
- Error 2.5% ‚Üí Some errors, check logs ‚ö†Ô∏è
- P95 = 800ms ‚Üí Some requests are very slow ‚ö†Ô∏è
- Should investigate which endpoint is slow

#### ‚ùå Failed Results

```json
{
  "requests": 2000,
  "rps": 33.33,
  "errorRate": 15,
  "latency": { "avg": 1200, "p95": 3000, "p99": 5000 }
}
```

**Analysis:**
- Error 15% ‚Üí Too many errors! ‚ùå
- Latency very high (avg 1.2 seconds) ‚ùå
- **Action needed:** Reduce VUs or optimize API

---

### ‚ñ≤ Finding the Breaking Point

How to find maximum API capacity:

```
1. Start with low VUs (e.g., 10)
2. Increase VUs by 2x (10 ‚Üí 20 ‚Üí 40 ‚Üí 80)
3. Observe metrics each round
4. Stop when:
   - Error rate > 5%
   - P95 latency > defined SLA
   - RPS doesn't increase despite more VUs (saturated)
```

```
VUs:     10   ‚Üí   20   ‚Üí   40   ‚Üí   80   ‚Üí  100
RPS:     50       98      180      190      185  ‚Üê saturated!
Error:   0%       0%       1%       8%      15%  ‚Üê breaking!
P95:    20ms    25ms     80ms    500ms   2000ms ‚Üê degraded!
                                   ‚Üë
                          Breaking Point = ~40 VUs
```

---

## ‚öô Available Scripts

| Script | Description |
|--------|-------------|
| `npm run build` | Build TypeScript ‚Üí JavaScript |
| `npm run build:watch` | Build in watch mode |
| `npm run test:sample` | Build + Run K6 test |
| `npm run test:sample:vus` | Run with custom VUs |
| `npm run typecheck` | Type check only (no emit) |

---

## ‚òê Requirements

- **Node.js** >= 18
- **K6** installed ([Install K6](https://k6.io/docs/get-started/installation/))
- **npm** or **pnpm**

---

## Goals

### Primary Goals

- Use single K6 setup to test multiple API projects
- Change test behavior through config
- Get **clear summary reports**

### Secondary Goals

- Reports readable by both developers and non-devs
- Export to file (JSON / HTML)
- Easy CI/CD integration

### Non-Goals (MVP)

- Real-time dashboard
- Advanced visualization
- Distributed reporting

---

## License

MIT
